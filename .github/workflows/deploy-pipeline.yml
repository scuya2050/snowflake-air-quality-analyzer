name: Deploy AQI SQL Objects

on:
  # Uncomment to enable automatic deployment on push
  # push:
  #   branches: [main]
  #   paths:
  #     - 'sql/ddl/0[1-5]-*.sql'
  #     - 'sql/dml/**'
  #     - '.github/workflows/deploy-pipeline.yml'
  
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - prod
      resume_task:
        description: 'Resume COPY task after deployment?'
        required: true
        default: false
        type: boolean

env:
  SNOWFLAKE_DATABASE: DEV_DB
  SNOWFLAKE_SCHEMA: PUBLIC
  SNOWFLAKE_ROLE: ACCOUNTADMIN
  SNOWFLAKE_WAREHOUSE: ADHOC_WH

jobs:
  deploy-sql-objects:
    name: Deploy SQL Objects
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'dev' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Install Snowflake CLI via dpkg
        run: |
          # Download the .deb package
          curl -L -O https://sfc-repo.snowflakecomputing.com/snowflake-cli/linux_x86_64/3.15.0/snowflake-cli-3.15.0.x86_64.deb
          
          # Install the package
          sudo dpkg -i snowflake-cli-3.15.0.x86_64.deb
          
          # Verify installation
          snow --version
          echo "Snowflake CLI installed"
      
      - name: Configure Snowflake Connection
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ORGANIZATION_NAME }}-${{ secrets.SNOWFLAKE_ACCOUNT_NAME }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        run: |  
          snow connection add \
            --connection-name deploy-conn \
            --account "$SNOWFLAKE_ACCOUNT" \
            --user "$SNOWFLAKE_USER" \
            --password "$SNOWFLAKE_PASSWORD" \
            --database "$SNOWFLAKE_DATABASE" \
            --schema "$SNOWFLAKE_SCHEMA" \
            --role "$SNOWFLAKE_ROLE" \
            --warehouse "$SNOWFLAKE_WAREHOUSE" \
            --default \
            --no-interactive
          
          # Test connection
          snow connection test --connection deploy-conn
          echo "Connection configured and tested"
      
      - name: Deploy DDL - Stage Layer
        run: |
          echo "Deploying Stage Layer..."
          snow sql -f sql/ddl/01-stage-layer.sql -c deploy-conn
          echo "Stage layer deployed"
      
      - name: Deploy DDL - Clean Layer
        run: |
          echo "Deploying Clean Layer..."
          snow sql -f sql/ddl/02-clean-layer.sql -c deploy-conn
          echo "Clean layer deployed"
      
      - name: Deploy DDL - Consumption Layer
        run: |
          echo "Deploying Consumption Layer..."
          snow sql -f sql/ddl/03-consumption-layer.sql -c deploy-conn
          echo "Consumption layer deployed"
      
      - name: Deploy DDL - Dimensional Model
        run: |
          echo "Deploying Dimensional Model..."
          snow sql -f sql/ddl/04-dimensional-model.sql -c deploy-conn
          echo "Dimensional model deployed"

      - name: Deploy DDL - Streamlit Views
        run: |
          echo "Deploying Streamlit Views..."
          snow sql -f sql/ddl/05-streamlit-views.sql -c deploy-conn
          echo "Streamlit Views deployed"
      
      - name: Deploy DML - Copy Task
        run: |
          echo "Deploying Copy Task..."
          snow sql -f sql/dml/01-copy-task.sql -c deploy-conn
          echo "Copy task deployed"
      
      - name: Resume Copy Task
        if: ${{ github.event.inputs.resume_task == 'true' }}
        run: |
          echo "Resuming Copy Task..."
          snow sql -q "ALTER TASK dev_db.stage_sch.copy_air_quality_data RESUME;" -c deploy-conn
          echo "Copy task resumed (will run hourly)"
      
      - name: Deployment Summary
        run: |
          echo "================================================"
          echo "Data Pipeline Deployment Complete!"
          echo "================================================"
          echo "DDL Scripts: 01 -> 02 -> 03 -> 04 -> 05"
          echo "DML Scripts: Copy task configured"
          if [ "${{ github.event.inputs.resume_task }}" == "true" ]; then
            echo "Task Status: RESUMED (ingesting data hourly)"
          else
            echo "Task Status: SUSPENDED (manual resume required)"
          fi
          echo "Pipeline ready for data ingestion"
          echo ""
          echo "Next Steps:"
          echo "  1. Run deploy-streamlit.yml to deploy dashboard"
          if [ "${{ github.event.inputs.resume_task }}" != "true" ]; then
            echo "  2. Resume COPY task: ALTER TASK dev_db.stage_sch.copy_air_quality_data RESUME;"
          fi
          echo "================================================"