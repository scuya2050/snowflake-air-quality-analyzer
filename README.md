# Snowflake Air Quality Analytics - End-to-End Data Engineering Project

[![Data Engineering](https://img.shields.io/badge/Data-Engineering-blue)](https://github.com)
[![Snowflake](https://img.shields.io/badge/Snowflake-Cloud%20Data%20Platform-29B5E8)](https://www.snowflake.com/)
[![Python](https://img.shields.io/badge/Python-3.8%2B-3776AB?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?logo=streamlit)](https://streamlit.io/)

## ğŸ“‹ Project Overview

This is a comprehensive end-to-end data engineering project that demonstrates modern data warehousing and analytics using Snowflake. The project ingests air quality data from multiple sources, processes it through a multi-layered architecture, and presents insights through interactive Streamlit dashboards.

### Key Features

- ğŸŒ **Multi-Source Data Integration**: API-based ingestion from India, Singapore, and UK air quality datasets
- ğŸ—ï¸ **Modern Data Architecture**: Implements staging, clean, and consumption layers
- ğŸ”„ **Automated Pipelines**: GitHub Actions for scheduled data ingestion
- ğŸ“Š **Interactive Dashboards**: Streamlit-based visualizations for air quality trends
- â˜ï¸ **Snowflake Features**: Dynamic tables, tasks, UDFs, and marketplace integration
- ğŸŒ¡ï¸ **Weather Integration**: Combines air quality with weather data from Snowflake Marketplace

## ğŸ›ï¸ Architecture

The project follows a modern medallion architecture pattern:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚
â”‚  (API/Files)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ingestion      â”‚â—„â”€â”€ GitHub Actions
â”‚  (Snowpark)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage Layer    â”‚  Raw JSON storage
â”‚  (dev_db)       â”‚  with metadata
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Clean Layer    â”‚  Flattened &
â”‚  (dev_db)       â”‚  Deduplicated
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Consumption     â”‚  Facts, Dimensions
â”‚     Layer       â”‚  & Aggregations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚  Interactive
â”‚   Dashboards    â”‚  Visualizations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
snowflake-e2e-project/
â”‚
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ .gitignore                   # Git ignore patterns
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ air_quality_hourly.yml  # Automated data ingestion pipeline
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dev.yaml                 # Development environment config
â”‚   â”œâ”€â”€ prod.yaml                # Production environment config
â”‚   â””â”€â”€ credentials.yaml.template  # Credentials template (DO NOT commit actual creds)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture/            # Architecture diagrams
â”‚   â”œâ”€â”€ setup-guide.md          # Detailed setup instructions
â”‚   â””â”€â”€ troubleshooting.md      # Common issues and solutions
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ ddl/                    # Data Definition Language scripts
â”‚   â”‚   â”œâ”€â”€ 01-db-schema-wh-ddl.sql
â”‚   â”‚   â”œâ”€â”€ 02-stage-layer-ddl-dml.sql
â”‚   â”‚   â””â”€â”€ 03-clean-layer-ddl-dml.sql
â”‚   â”œâ”€â”€ dml/                    # Data Manipulation Language scripts
â”‚   â”‚   â”œâ”€â”€ 04-clean-transpose-table.sql
â”‚   â”‚   â”œâ”€â”€ 05-wide-table-consumption.sql
â”‚   â”‚   â”œâ”€â”€ 06-fact-and-dim.sql
â”‚   â”‚   â”œâ”€â”€ 07-aggregated-fact-table.sql
â”‚   â”‚   â”œâ”€â”€ 08-loading-additional-data.sql
â”‚   â”‚   â””â”€â”€ 09-data-sharing-agg-fact.sql
â”‚   â””â”€â”€ functions/              # User-Defined Functions
â”‚
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”‚   â””â”€â”€ ingest-api-data.py  # API data ingestion script
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ snowflake_connector.py  # Snowflake connection utilities
â”‚   â”‚       â””â”€â”€ config_loader.py        # Configuration loader
â”‚   â””â”€â”€ tests/                  # Unit tests
â”‚
â”œâ”€â”€ streamlit/
â”‚   â”œâ”€â”€ pages/                  # Streamlit dashboard pages
â”‚   â”‚   â”œâ”€â”€ 01-air-quality-trend-city-day-level.py
â”‚   â”‚   â”œâ”€â”€ 02-air-quality-trend-city-hour-level.py
â”‚   â”‚   â”œâ”€â”€ 03-air-quality-map.py
â”‚   â”‚   â”œâ”€â”€ 04-air-quality-map-bubble.py
â”‚   â”‚   â””â”€â”€ 05-delhi-aqi.py
â”‚   â”œâ”€â”€ utils/                  # Dashboard utilities
â”‚   â”œâ”€â”€ requirements.txt        # Streamlit-specific dependencies
â”‚   â””â”€â”€ config.toml            # Streamlit configuration
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ samples/           # Sample data files (for testing)
â”‚   â””â”€â”€ processed/             # Processed data (local testing only)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup/
â”‚   â”‚   â””â”€â”€ initial_setup.sh   # Initial project setup script
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â””â”€â”€ deploy.py          # Deployment automation
â”‚   â””â”€â”€ maintenance/
â”‚       â””â”€â”€ cleanup.py         # Cleanup utilities
â”‚
â””â”€â”€ exercises/                 # Learning exercises and tutorials
```

## ğŸš€ Getting Started

### Prerequisites

- **Snowflake Account**: Sign up at [snowflake.com](https://signup.snowflake.com/)
- **Python 3.8+**: [Download Python](https://www.python.org/downloads/)
- **Git**: [Download Git](https://git-scm.com/downloads)
- **Air Quality API Key**: Register at your preferred air quality data provider

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd snowflake-e2e-project
   ```

2. **Set up Python virtual environment**
   ```bash
   python -m venv venv
   
   # On Windows
   .\venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure credentials**
   ```bash
   # Copy the template
   cp config/credentials.yaml.template config/credentials.yaml
   
   # Edit with your Snowflake credentials
   # âš ï¸ NEVER commit this file to Git!
   ```

5. **Set up Snowflake objects**
   ```bash
   # Run the DDL scripts in order
   # Execute sql/ddl/*.sql in Snowflake worksheet
   ```

6. **Configure environment variables**
   ```bash
   # Windows PowerShell
   $env:SNOWFLAKE_ACCOUNT="your-account"
   $env:SNOWFLAKE_USER="your-username"
   $env:SNOWFLAKE_PASSWORD="your-password"
   
   # Linux/macOS
   export SNOWFLAKE_ACCOUNT="your-account"
   export SNOWFLAKE_USER="your-username"
   export SNOWFLAKE_PASSWORD="your-password"
   ```

### Quick Start

1. **Run data ingestion**
   ```bash
   python python/src/ingestion/ingest-api-data.py
   ```

2. **Launch Streamlit dashboard**
   ```bash
   cd streamlit
   streamlit run pages/01-air-quality-trend-city-day-level.py
   ```

## ğŸ“Š Data Pipeline

### 1. Ingestion Layer
- **Source**: Air quality APIs (India, Singapore, UK)
- **Frequency**: Hourly (via GitHub Actions)
- **Technology**: Snowpark Python
- **Output**: Raw JSON in Snowflake stage tables

### 2. Stage Layer (Bronze)
- **Schema**: `dev_db.stage_sch`
- **Format**: Semi-structured JSON with metadata
- **Purpose**: Landing zone for raw data

### 3. Clean Layer (Silver)
- **Schema**: `dev_db.clean_sch`
- **Transformations**:
  - JSON flattening
  - Deduplication
  - Data type standardization
  - Data quality checks

### 4. Consumption Layer (Gold)
- **Schema**: `dev_db.consumption_sch`
- **Objects**:
  - Fact tables (aggregated air quality metrics)
  - Dimension tables (location, time)
  - Wide tables for analytics
  - Dynamic tables for real-time updates

### 5. Visualization Layer
- **Technology**: Streamlit
- **Features**:
  - City-level daily/hourly trends
  - Interactive maps with AQI markers
  - Bubble maps for multi-metric analysis
  - Delhi-specific deep dives

## ğŸ”§ Technologies Used

| Category | Technology | Purpose |
|----------|-----------|---------|
| **Data Warehouse** | Snowflake | Cloud data platform |
| **Data Processing** | Snowpark Python | Data transformation |
| **Orchestration** | GitHub Actions | Automated workflows |
| **Visualization** | Streamlit | Interactive dashboards |
| **Language** | Python 3.8+ | Scripting and automation |
| **Version Control** | Git | Source code management |

## ğŸŒŸ Snowflake Features Demonstrated

- âœ… **Dynamic Tables**: Auto-refreshing materialized views
- âœ… **Tasks**: Scheduled job execution
- âœ… **Streams**: Change Data Capture (CDC)
- âœ… **Stages**: External and internal data staging
- âœ… **File Formats**: JSON parsing and schema inference
- âœ… **Marketplace**: Integration with Weather data
- âœ… **UDFs**: Custom SQL functions
- âœ… **Resource Monitors**: Cost control
- âœ… **Role-Based Access Control (RBAC)**

## ğŸ“ˆ Sample Dashboards

The project includes 5 interactive Streamlit dashboards:

1. **City-Day Trends**: Daily air quality patterns across cities
2. **City-Hour Trends**: Hourly granularity for detailed analysis
3. **Map View**: Geographical distribution of AQI
4. **Bubble Map**: Multi-dimensional pollutant visualization
5. **Delhi Deep Dive**: Focused analysis on Delhi air quality

## ğŸ” Security Best Practices

- âŒ **NEVER** commit credentials to Git
- âœ… Use environment variables for sensitive data
- âœ… Keep `config/credentials.yaml` in `.gitignore`
- âœ… Use Snowflake service accounts for automation
- âœ… Implement row-level security where needed
- âœ… Regularly rotate passwords and API keys

## ğŸ“š Learning Resources

- [Snowflake Documentation](https://docs.snowflake.com/)
- [Snowpark Python Guide](https://docs.snowflake.com/en/developer-guide/snowpark/python/index.html)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Air Quality API Documentation](https://aqicn.org/api/)

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is for educational purposes. Please ensure compliance with data provider terms of service.

## ğŸ› Troubleshooting

See [docs/troubleshooting.md](docs/troubleshooting.md) for common issues and solutions.

## ğŸ“ Contact

For questions or feedback, please open an issue in the repository.

---

**Built with â„ï¸ Snowflake and ğŸ Python**
